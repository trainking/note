# MongoDB最佳实践

## 复制集

MongoDB使用**复制集**实现高可用机制。MongoDB中的复制集（Replica Set）是一组MongoDB实例的集合，用于提供数据冗余和高可用性。复制集中包含一个主节点（Primary）和多个从节点（Secondary），主节点处理所有写操作，并将数据同步到从节点，从节点只能读取数据。如果主节点出现故障或不可用，复制集会自动选择一个从节点作为新的主节点，以保证系统的可用性和数据完整性。

**复制集**通过选举完成故障恢复。它有以下特点：

* 具有投票权的的节点之间互相发送心跳（保活）
* 当5次心跳未收到时判断为失联节点
* 如果失联的主节点，从节点会发起选举，选出新的主节点
* 如果失联的时从节点，不会重新产生选举
* 选举基于RAFT一致性算法实现，选举成功的必要条件时大多数投票节点存活
* 复制集最多可以有50个，但具有投票权的最多7个

### 实践

#### 1. 准备工作

MondoDB启动时，会使用一个本地磁盘的目录作为数据目录。本机存在多个复制集，需要保证他们不在同一目录下。一个配置复制集的配置文件：

```
# /data1/mongod.conf
systemLog:
  destination: file
  path: /data1/mongod.log   # 日志文件路径
  logAppend: true
storage:
  dbPath: /data1    # 数据目录
net:
  bindIp: 0.0.0.0
  port: 28017   # 端口
replication:
  replSetName: rs0
processManagement:
  fork: true   # 进程作为后台进程独立运行
```

> 启用了`replication`参数才表明是一个复制集，默认是单例。

使用`mongod -f`指定配置文件启动。

#### 2. 配置复制集

使用命令行进入主机：

```shell
mongo --port 28017
```

进入命令行后，使用`rs`命令配置:

```shell
rs.initiate({
    _id: "rs0",
    members: [{
        _id: 0,
        host: "localhost:28017"
    },{
        _id: 1,
        host: "localhost:28018"
    },{
        _id: 2,
        host: "localhost:28019"
    }]
})
```

查看复制集的状态:

```
rs.status()
```

从节点可读：

```
rs.slaveOK()
```

## 模型设计

数据模型是一组由符号，文本组成的集合，用以准确的表达信息，达到有效叫交流和沟通目的。一个数据模型由三个元素组成：**实体（Entity）**， **属性（Attribute）**，**关系（Relationship）**。

实体是属性的集合，属性是数据的最小单位；关系描述实体与实体之间的数据规则。数据模型的三层深度：**概念模型->逻辑模型->物理模型**；是以恶搞模型逐步细化实现的过程。

MongoDB的数据模型是基于**文档模型**的，所以它的数据模型设计。与关系型数据库，最大的不同，表示关系时不再使用外键这样的形势，而是利用**内嵌数组**或者引用字段等方式表达关系。

### 基础设计

MongoDB设置文档模型，采取三步：

1. 基础建模：从需求中，明确集合，字段，和基础的形状
2. 工况细化：处理模型之间的引用，关联；也就是设计实体之间的关系
3. 套用设计模式：通过经验，优化

#### 基础建模

设计关系模型时，需要注意以下几点：

1. 1-1模型：最佳使用内嵌文档方式
2. 1-N模型：以内嵌数组为主，数组中仅联系关联数据，不做冗余；例外情况，数组太大（数万或者不确定）不应该使用内嵌
3. N-N模型：可以使用内嵌数组为主，同样要考虑文档大小，如果无法解决，使用映射表

> MongoDB一个文档的不能超过16MB，设计时需要考虑这一点

#### 工况细化

工况细化，是针对业务设计做出一些特化修改。例如：某些数据在是读多写少，还是写入一次，之后不再变化。数据量的大小，常用的查询参数等等。根据这些需求，需要适当的设计一些引用或者冗余，减少性能的开销，和业务的开发难度。

> MongoDB从3以后，聚合查询增加了`$lookup`用于连表查询

引用设计限制：

1. MongoDB对应用的集合之间无主外键检查
2. MongoDB使用聚合查询的`$lookup`模仿关联查询，且只支持`left outer join`
3. `$lookup`的关联目标(from)不能是分片表

#### 模式套用


**列转行**

* 问题： 大文档，很多字段，很多索引
* 模式：列转行模式，将用列描述的数据，通过内嵌文档的模式，转化为行数据；减少索引，减少字段

**版本控制**

* 问题：模型灵活，行的字段不确定，如何管理不同文档的版本？
* 模式： 增加一个版本字段，描述行的版本；无设置默认值

**近似计算**

* 问题：实时统计的频繁写入
* 模式：统计数字并发精确，可以使用近似计算。写入时，增加一个`if random(0,9) == 0`时，写入

**预聚合**

* 问题：精确统计问题，游戏排名
* 模式：在文档中，增加几个统计字段，在更新时，通过`$inc`进行预聚合

## 事务

### 写操作事务

#### writeConcern

`writeConcern`时MongoDB中，决定一个写操作落到多少个节点上算写入成功。它的取值包括：

* 0: 发起写操作，不关心是否成功
* 1-max节点数：写操作需要落到多少个节点上才算成功
* majority：写操作需要被复制到大多数节点（超过半数）才算成功
* all：写操作必须写入到所有节点

> 节点复制集不做任何设定（默认值），为了保证数据写入不丢，建议使用`majority`。

```
db.test.insert({count:1}, {writeConcern: {w: "marjority"}})
```

#### journal

wrireConcern决定写操作到达多少个节点才算成功，`journal`则定义了如何才算成功，取值包括：

* true: 写操作落到journal文件才算成功
* false: 写操作到达内存就算成功

```
{j：true}
```

### 读操作事务

在分布式数据库中，读操作需要明确两个问题：

1. 从哪里读？关注数据节点所在的位置
2. 什么样的数据可以读？关注数据的隔离性

在MongoDB中，第一个问题使用`readPreference`解决，第二个问题使用`readConcern`解决。

#### readPreference

readPreference决定使用哪一个节点，满足读请求，取值包括：

* primary: 只选择主节点
* primaryPreferred：优先选择主节点，如不可选，则选从节点
* secondary：只选择从节点
* secondaryPreferred：优选选择从节点，如果从节点不可选，则选择主节点
* nearest：选择最近节点，距离时通过ping time来决定的

readPreference只能控制选择一类节点。通过给节点设置Tag，控制选择一个节点还是几个节点。

> 在MongoDB中，Tag是指用于分片的标记，也称为shard key

如何来指定readPreference，有以下途径：

1. 通过连接url增加参数
2. MongoDB的驱动API增加参数
3. Mongo Shell，为每一个操作增加此参数

#### readConcern

readConcern决定了一个节点上的数据，哪些时可读的，类似与关系型数据库的隔离级别。可选值包括：

* availbale：读所有可用的数据
* local：读取所有可用且属于当前分片的数据
* majority：读取在大多数节点上提交完成的数据
* linearizable：可线性化读取文档
* snapshot：读取最近快照中的数据

在复制集中`local`和`available`是**没有区别的**。两者的区别主要体现在分片集上。在进行分片的Chunk迁移时，指定local，只读取本地数据。**从主节点中读取数据时，默认是local。从从节点读取数据时，默认时available（向前兼容原因）。**
MongoDB中，通过MVCC机制，维护不同版本的一致性。